# Chatbot Configuration Update - Phi-3 Small Setup

## Changes Made

### 1. Updated Chatbot to Use Phi-3 Mini (Small & Fast)

**Previous Setup:**
- Port 8005: Mistral 7B (slow but accurate)
- Chatbot was trying to call FastAPI `/ask` endpoint (which doesn't exist)

**New Setup:**
- **Port 8005: Phi-3 Mini** (fast & efficient) ‚úÖ **ACTIVE FOR CHATBOT**
- **Port 8006: Mistral 7B** (available as backup)
- Direct Ollama API calls (no FastAPI wrapper needed)

### 2. Files Modified

#### `routes/web.php` - Chatbot API Route
**Changed:**
- Model: `mistral:7b` ‚Üí `phi3:mini`
- Endpoint: `http://localhost:8005/ask` ‚Üí `http://localhost:8005/api/generate`
- API format: FastAPI style ‚Üí Ollama native API
- Added 60-second timeout for longer responses

**New API Call:**
```php
$data = [
    'model' => 'phi3:mini',
    'prompt' => $message,
    'stream' => false
];
```

#### `resources/views/admin/chatbot-settings.blade.php` - UI Display
**Changed:**
- Model display: "mistral:7b" ‚Üí "phi3:mini (Phi-3 Small)"
- Description: "Running on RunPod via SSH tunnel" ‚Üí "Fast & efficient - Port 8005 | Mistral 7B on Port 8006"

## Available Models on Each Port

### Port 8005 (Primary - Chatbot)
- ‚úÖ **phi3:mini** (2.1 GB) - **ACTIVE** for chatbot
- phi3:latest (2.1 GB)
- mistral:7b (4.4 GB)
- all-minilm:l6-v2 (46 MB) - Embeddings
- nomic-embed-text:latest (274 MB) - Embeddings

### Port 8006 (Backup)
- mistral:7b (4.4 GB) - Available for slower, more detailed responses
- Same models as 8005

### Port 8007 (RAG Processing)
- Used for document embedding generation
- all-minilm:l6-v2 model

## Performance Comparison

### Phi-3 Mini (Port 8005) ‚úÖ **CURRENT**
- **Speed:** Fast (~2-5 seconds per response)
- **Model Size:** 2.1 GB
- **Best For:** Quick questions, conversational responses, farm advice
- **Context Window:** 128K tokens
- **Quality:** Good for most tasks

### Mistral 7B (Port 8006)
- **Speed:** Slower (~10-20 seconds per response)
- **Model Size:** 4.4 GB
- **Best For:** Complex analysis, detailed explanations
- **Context Window:** 32K tokens
- **Quality:** Higher accuracy for complex tasks

## Testing

### Direct Ollama Test (Successful ‚úÖ)
```bash
curl -s -X POST http://localhost:8005/api/generate \
  -H "Content-Type: application/json" \
  -d '{"model":"phi3:mini","prompt":"What is biodynamic farming?","stream":false}'
```

**Response:**
> "Biodynamic farming is an ecological, ethical approach to food production that views the farm as a self-sustaining system. It emphasizes spiritual and cosmic influences on agricultural practices..."

### Chatbot Page Test
Visit: https://admin.middleworldfarms.org:8444/admin/chatbot-settings

**Features:**
- ‚úÖ AI Service Status (shows online/offline)
- ‚úÖ Test Connection button
- ‚úÖ Live chat interface
- ‚úÖ Quick question buttons
- ‚úÖ Response time tracking

## How to Use the Chatbot

### Access the Page
URL: `https://admin.middleworldfarms.org:8444/admin/chatbot-settings`

### Test Questions
Click the quick question buttons or ask:
- "What should I plant this week?"
- "How do I prepare biodynamic preparations?"
- "When is the best time to harvest Brussels sprouts?"
- "How do I manage pests naturally?"
- "What are moon phases for farming?"

### Expected Behavior
1. Type question in chat box
2. Click "Send" or press Enter
3. Response appears in ~2-5 seconds (much faster than Mistral!)
4. Response time shown in sidebar

## Switching Between Models (If Needed)

### To Use Mistral 7B (Slower, More Detailed)
Edit `routes/web.php` line ~196:
```php
// Change this:
'model' => 'phi3:mini',

// To this:
'model' => 'mistral:7b',
```

Then clear cache:
```bash
php -r "opcache_reset();"
```

### To Use Different Port
Change port in `routes/web.php`:
```php
// Port 8005 (Phi-3) - Current
$response = file_get_contents('http://localhost:8005/api/generate', ...);

// Port 8006 (Mistral backup)
$response = file_get_contents('http://localhost:8006/api/generate', ...);
```

## RAG Integration (Future Enhancement)

Currently the chatbot uses **direct Ollama** without RAG (Retrieval Augmented Generation).

### To Enable RAG with Your Uploaded PDFs:
1. Ensure RAG queue processing completed (check Settings page)
2. Create a RAG query service that:
   - Searches vector database for relevant chunks
   - Passes chunks as context to Phi-3
   - Returns answer based on your documents

### RAG Benefits:
- Answers based on your specific farm documents
- Cites sources from uploaded PDFs
- More accurate for your specific use case

## Troubleshooting

### If Chatbot Shows "Offline"
```bash
# Check if Ollama is running on port 8005
netstat -tlnp | grep 8005

# Test direct connection
curl http://localhost:8005/api/tags
```

### If Responses Are Slow
- ‚úÖ Already using Phi-3 Mini (fastest model)
- Check server load: `top`
- Consider reducing response length in prompt

### If Model Not Found
```bash
# List available models
curl http://localhost:8005/api/tags | python3 -m json.tool

# Pull model if missing
OLLAMA_HOST=localhost:8005 ollama pull phi3:mini
```

## Production Checklist

- ‚úÖ Phi-3 Mini configured on port 8005
- ‚úÖ Chatbot page updated to show correct model
- ‚úÖ API route updated for Ollama direct calls
- ‚úÖ OPcache cleared
- ‚úÖ Tested with farming questions
- ‚è≥ RAG integration (future enhancement)
- ‚è≥ Response caching (future optimization)

## Next Steps

1. **Test the chatbot page** at https://admin.middleworldfarms.org:8444/admin/chatbot-settings
2. **Compare speed** - should be much faster than Mistral
3. **Integrate RAG** - connect chatbot to your uploaded PDF knowledge base
4. **Add conversation history** - track and learn from user questions
5. **Fine-tune prompts** - optimize for farm-specific responses

## Model Information

### Phi-3 Mini Details
- **Family:** Microsoft Phi-3
- **Parameters:** 3.8B
- **Quantization:** Q4_0 (4-bit)
- **Size:** 2.1 GB
- **Released:** April 2024
- **Trained on:** Web data, books, code
- **Special:** Small Language Model (SLM) - efficient for edge deployment

### Why Phi-3 Mini is Perfect for Your Use Case:
1. ‚úÖ **Fast responses** - Better user experience
2. ‚úÖ **Lower resource usage** - Won't slow down server
3. ‚úÖ **Good quality** - Excellent for Q&A and farm advice
4. ‚úÖ **Large context window** - Can handle long conversations
5. ‚úÖ **Optimized for chat** - Designed for conversational AI

## Summary

Your chatbot is now configured to use **Phi-3 Mini on port 8005** for fast, efficient responses. Mistral 7B remains available on port 8006 if you need more detailed analysis for specific tasks.

**Status: READY TO USE** üöÄ

Visit the chatbot page and start asking questions!
